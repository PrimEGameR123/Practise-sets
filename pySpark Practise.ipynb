{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e085f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c96d28e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dbe3d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Spark\\spark-3.3.0-bin-hadoop3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.environ['SPARK_HOME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c911c2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName('Practise').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9ea5abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://Hare-Krishna:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practise</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x230615f2df0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "748daa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inferschema enables the spark to understand the dtype of columns\n",
    "dfpyspark=spark.read.csv(r'C:\\Users\\DELL\\spark.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc18251",
   "metadata": {},
   "source": [
    "<h6> or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0b7ab48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpyspark=spark.read.option('header','true').csv(r'C:\\Users\\DELL\\spark.csv',inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b0bf6b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+----+\n",
      "|Name|Experience| Age|\n",
      "+----+----------+----+\n",
      "|   a|         5|  21|\n",
      "|   b|         6|  22|\n",
      "|   c|         7|  21|\n",
      "|   d|         8|  21|\n",
      "|   e|         9|  21|\n",
      "|   f|        10|  22|\n",
      "|null|      null|null|\n",
      "|null|      null|  21|\n",
      "|null|        13|  21|\n",
      "+----+----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfpyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ed03922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is pyspark dataframe not pandas dataframe\n",
    "type(dfpyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a9615711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfpyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4f2d9417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name', 'Experience', 'Age']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfpyspark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7884bd86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Name='a', Experience=5, Age=21)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfpyspark.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f0094719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Name='a', Experience=5, Age=21, Age after 2 years=23),\n",
       " Row(Name='b', Experience=6, Age=21, Age after 2 years=23),\n",
       " Row(Name='c', Experience=7, Age=21, Age after 2 years=23)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfpyspark.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4c45124e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'Name'>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfpyspark['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8da50a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+\n",
      "|Name|Experience|\n",
      "+----+----------+\n",
      "|   a|         5|\n",
      "|   b|         6|\n",
      "|   c|         7|\n",
      "|   d|         8|\n",
      "|   e|         9|\n",
      "|   f|        10|\n",
      "|null|      null|\n",
      "|null|      null|\n",
      "|null|        13|\n",
      "+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfpyspark.select(['Name','Experience']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fdd252fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Name', 'string'), ('Experience', 'int'), ('Age', 'int')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfpyspark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ab3fc2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----------------+-------------------+\n",
      "|summary|Name|       Experience|                Age|\n",
      "+-------+----+-----------------+-------------------+\n",
      "|  count|   6|                7|                  8|\n",
      "|   mean|null|8.285714285714286|              21.25|\n",
      "| stddev|null|2.690370836538197|0.46291004988627565|\n",
      "|    min|   a|                5|                 21|\n",
      "|    max|   f|               13|                 22|\n",
      "+-------+----+-----------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfpyspark.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2232149e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding column\n",
    "dfpyspark=dfpyspark.withColumn('Age after 2 years',dfpyspark['Age']+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7fe3c77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+----+-----------------+\n",
      "|Name|Experience| Age|Age after 2 years|\n",
      "+----+----------+----+-----------------+\n",
      "|   a|         5|  21|               23|\n",
      "|   b|         6|  22|               24|\n",
      "|   c|         7|  21|               23|\n",
      "|   d|         8|  21|               23|\n",
      "|   e|         9|  21|               23|\n",
      "|   f|        10|  22|               24|\n",
      "|null|      null|null|             null|\n",
      "|null|      null|  21|               23|\n",
      "|null|        13|  21|               23|\n",
      "+----+----------+----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfpyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8a082ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+----+\n",
      "|Name|Experience| Age|\n",
      "+----+----------+----+\n",
      "|   a|         5|  21|\n",
      "|   b|         6|  22|\n",
      "|   c|         7|  21|\n",
      "|   d|         8|  21|\n",
      "|   e|         9|  21|\n",
      "|   f|        10|  22|\n",
      "|null|      null|null|\n",
      "|null|      null|  21|\n",
      "|null|        13|  21|\n",
      "+----+----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#drop the column\n",
    "dfpyspark=dfpyspark.drop('Age after 2 years')\n",
    "dfpyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "50be03dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----+\n",
      "|First_Name|Experience| Age|\n",
      "+----------+----------+----+\n",
      "|         a|         5|  21|\n",
      "|         b|         6|  22|\n",
      "|         c|         7|  21|\n",
      "|         d|         8|  21|\n",
      "|         e|         9|  21|\n",
      "|         f|        10|  22|\n",
      "|      null|      null|null|\n",
      "|      null|      null|  21|\n",
      "|      null|        13|  21|\n",
      "+----------+----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# rename\n",
    "dfpyspark=dfpyspark.withColumnRenamed('Name','First_Name')\n",
    "dfpyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8f02e0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---+\n",
      "|First_Name|Experience|Age|\n",
      "+----------+----------+---+\n",
      "|         a|         5| 21|\n",
      "|         b|         6| 22|\n",
      "|         c|         7| 21|\n",
      "|         d|         8| 21|\n",
      "|         e|         9| 21|\n",
      "|         f|        10| 22|\n",
      "+----------+----------+---+\n",
      "\n",
      "+----------+----------+---+\n",
      "|First_Name|Experience|Age|\n",
      "+----------+----------+---+\n",
      "|         a|         5| 21|\n",
      "|         b|         6| 22|\n",
      "|         c|         7| 21|\n",
      "|         d|         8| 21|\n",
      "|         e|         9| 21|\n",
      "|         f|        10| 22|\n",
      "+----------+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dropping all na rows\n",
    "dfpyspark.na.drop().show()\n",
    "## or\n",
    "dfpyspark.dropna().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f846196e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---+\n",
      "|First_Name|Experience|Age|\n",
      "+----------+----------+---+\n",
      "|         a|         5| 21|\n",
      "|         b|         6| 22|\n",
      "|         c|         7| 21|\n",
      "|         d|         8| 21|\n",
      "|         e|         9| 21|\n",
      "|         f|        10| 22|\n",
      "|      null|      null| 21|\n",
      "|      null|        13| 21|\n",
      "+----------+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dropping only those where all values are null\n",
    "dfpyspark.na.drop(how='all').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c6fa6673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---+\n",
      "|First_Name|Experience|Age|\n",
      "+----------+----------+---+\n",
      "|         a|         5| 21|\n",
      "|         b|         6| 22|\n",
      "|         c|         7| 21|\n",
      "|         d|         8| 21|\n",
      "|         e|         9| 21|\n",
      "|         f|        10| 22|\n",
      "|      null|        13| 21|\n",
      "+----------+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfpyspark.na.drop(how='any',thresh=2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "445f61b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---+\n",
      "|First_Name|Experience|Age|\n",
      "+----------+----------+---+\n",
      "|         a|         5| 21|\n",
      "|         b|         6| 22|\n",
      "|         c|         7| 21|\n",
      "|         d|         8| 21|\n",
      "|         e|         9| 21|\n",
      "|         f|        10| 22|\n",
      "|      null|        13| 21|\n",
      "+----------+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using only particular columns removing the null values.\n",
    "dfpyspark.na.drop(subset=['Experience','Age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "45b15f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----+\n",
      "|First_Name|Experience| Age|\n",
      "+----------+----------+----+\n",
      "|         a|         5|  21|\n",
      "|         b|         6|  22|\n",
      "|         c|         7|  21|\n",
      "|         d|         8|  21|\n",
      "|         e|         9|  21|\n",
      "|         f|        10|  22|\n",
      "|   Missing|      null|null|\n",
      "|   Missing|      null|  21|\n",
      "|   Missing|        13|  21|\n",
      "+----------+----------+----+\n",
      "\n",
      "+----------+----------+---+\n",
      "|First_Name|Experience|Age|\n",
      "+----------+----------+---+\n",
      "|         a|         5| 21|\n",
      "|         b|         6| 22|\n",
      "|         c|         7| 21|\n",
      "|         d|         8| 21|\n",
      "|         e|         9| 21|\n",
      "|         f|        10| 22|\n",
      "|      null|         0|  0|\n",
      "|      null|         0| 21|\n",
      "|      null|        13| 21|\n",
      "+----------+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filling the missing values\n",
    "dfpyspark.na.fill('Missing').show() \n",
    "dfpyspark.na.fill(0).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c57684",
   "metadata": {},
   "source": [
    "Only the same dtype columns are filled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3c85ec29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---+\n",
      "|First_Name|Experience|Age|\n",
      "+----------+----------+---+\n",
      "|         a|         5| 21|\n",
      "|         b|         6| 22|\n",
      "|         c|         7| 21|\n",
      "|         d|         8| 21|\n",
      "|         e|         9| 21|\n",
      "|         f|        10| 22|\n",
      "|   Missing|         0|  0|\n",
      "|   Missing|         0| 21|\n",
      "|   Missing|        13| 21|\n",
      "+----------+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# So\n",
    "dfpyspark.na.fill('Missing')\\\n",
    "    .na.fill(0).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c0c9731d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---+\n",
      "|First_Name|Experience|Age|\n",
      "+----------+----------+---+\n",
      "|         a|         5| 21|\n",
      "|         b|         6| 22|\n",
      "|         c|         7| 21|\n",
      "|         d|         8| 21|\n",
      "|         e|         9| 21|\n",
      "|         f|        10| 22|\n",
      "|   Missing|         0|  0|\n",
      "|   Missing|         0| 21|\n",
      "|   Missing|        13| 21|\n",
      "+----------+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# or by using subset\n",
    "dfpyspark.na.fill({'First_Name':'Missing','Age':0,'Experience':0}).show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41c9169",
   "metadata": {},
   "source": [
    "##### using imputer to replace null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b9938ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "impute=Imputer(\n",
    "    inputCols=['Experience','Age'],\n",
    "    outputCols=[\"{}_imputed\".format(c) for c in ['Experience','Age']]).setStrategy('median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6a29e257",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpyspark=impute.fit(dfpyspark).transform(dfpyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e57cebab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----+------------------+-----------+\n",
      "|First_Name|Experience| Age|Experience_imputed|Age_imputed|\n",
      "+----------+----------+----+------------------+-----------+\n",
      "|         a|         5|  21|                 5|         21|\n",
      "|         b|         6|  22|                 6|         22|\n",
      "|         c|         7|  21|                 7|         21|\n",
      "|         d|         8|  21|                 8|         21|\n",
      "|         e|         9|  21|                 9|         21|\n",
      "|         f|        10|  22|                10|         22|\n",
      "|      null|      null|null|                 8|         21|\n",
      "|      null|      null|  21|                 8|         21|\n",
      "|      null|        13|  21|                13|         21|\n",
      "+----------+----------+----+------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfpyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8a94bbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpyspark=dfpyspark.drop('Experience_imputed','Age_imputed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1208e6",
   "metadata": {},
   "source": [
    "#### using other method to replace null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "2d148dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---+\n",
      "|First_Name|Experience|Age|\n",
      "+----------+----------+---+\n",
      "|         a|         5| 21|\n",
      "|         b|         6| 22|\n",
      "|         c|         7| 21|\n",
      "|         d|         8| 21|\n",
      "|         e|         9| 21|\n",
      "|         f|        10| 22|\n",
      "|   Unknown|         8| 21|\n",
      "|   Unknown|         8| 21|\n",
      "|   Unknown|        13| 21|\n",
      "+----------+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfpyspark=dfpyspark.na.fill({'First_Name':'Unknown','Experience':np.mean(dfpyspark.select('Experience').dropna().collect()),\n",
    "                   'Age':np.median(dfpyspark.select('Age').dropna().collect())})\n",
    "dfpyspark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e2055e",
   "metadata": {},
   "source": [
    "## Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "2ec9f054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|First_Name|\n",
      "+----------+\n",
      "|         a|\n",
      "|         b|\n",
      "|         c|\n",
      "|         d|\n",
      "|         e|\n",
      "|   Unknown|\n",
      "|   Unknown|\n",
      "|   Unknown|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfpyspark.filter((dfpyspark['Age']==21) | (dfpyspark['Experience']<10)).select(['First_Name']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "7ca24e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|First_Name|\n",
      "+----------+\n",
      "|         f|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# not\n",
    "dfpyspark.filter(~((dfpyspark['Age']==21) | (dfpyspark['Experience']<10))).select(['First_Name']).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
